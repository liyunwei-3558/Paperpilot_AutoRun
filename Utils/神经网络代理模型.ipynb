{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "True\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "# import gpytorch\n",
    "# from gpytorch import kernels, means, models, mlls, settings\n",
    "# from gpytorch import distributions as distr\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "train_size = 25000\n",
    "test_size = 10000\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../records/initial.csv')\n",
    "data.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "data.head()\n",
    "data2 = data.apply(lambda x : (x-np.min(x))/(np.max(x)-np.min(x)))\n",
    "data2.result = data.result\n",
    "data2.to_csv('../records/normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train = data.iloc[:train_size,: ]\n",
    "test = data.iloc[train_size:, :]\n",
    "train_x = data.iloc[0:train_size,:-1]\n",
    "train_y = data.iloc[0:train_size,-1]\n",
    "test_x = data.iloc[train_size:train_size+test_size, :-1]\n",
    "test_y = data.iloc[train_size:train_size+test_size, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(np.array(train_x))\n",
    "train_y = torch.from_numpy(np.array(train_y))\n",
    "test_x = torch.from_numpy(np.array(test_x))\n",
    "test_y = torch.from_numpy(np.array(test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# print(torch.cuda.is_available())\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Weight  Elevators  theta  rou  result\n0          48         46     35  105    44.0\n1           9         42     41   95    42.8\n2          87         36     38  110     9.8\n3          50         15     50   85    41.8\n4         100         71     41  110    46.3\n...       ...        ...    ...  ...     ...\n24995      39         42     41  115    16.4\n24996       5         28     48   80    46.4\n24997      87         42     41  105    42.4\n24998      99         22     41  105    11.9\n24999      87         30     35  100     6.8\n\n[25000 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Weight</th>\n      <th>Elevators</th>\n      <th>theta</th>\n      <th>rou</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48</td>\n      <td>46</td>\n      <td>35</td>\n      <td>105</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>42</td>\n      <td>41</td>\n      <td>95</td>\n      <td>42.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>87</td>\n      <td>36</td>\n      <td>38</td>\n      <td>110</td>\n      <td>9.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50</td>\n      <td>15</td>\n      <td>50</td>\n      <td>85</td>\n      <td>41.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>71</td>\n      <td>41</td>\n      <td>110</td>\n      <td>46.3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>39</td>\n      <td>42</td>\n      <td>41</td>\n      <td>115</td>\n      <td>16.4</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>5</td>\n      <td>28</td>\n      <td>48</td>\n      <td>80</td>\n      <td>46.4</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>87</td>\n      <td>42</td>\n      <td>41</td>\n      <td>105</td>\n      <td>42.4</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>99</td>\n      <td>22</td>\n      <td>41</td>\n      <td>105</td>\n      <td>11.9</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>87</td>\n      <td>30</td>\n      <td>35</td>\n      <td>100</td>\n      <td>6.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 82
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 32\n",
    "num_epoches = 20\n",
    "lr = 0.5\n",
    "momentum = 0.9\n",
    "#归一化\n",
    "\n",
    "normal_train = train.apply(lambda x : (x-np.min(x))/(np.max(x)-np.min(x)))\n",
    "normal_train.result = train.result\n",
    "normal_test = test.apply(lambda x : (x-np.min(x))/(np.max(x)-np.min(x)))\n",
    "normal_test.result = test.result\n",
    "\n",
    "class PilotDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        \"\"\"\n",
    "        纸飞机dataset\n",
    "        :param data_dir: Dataframe\n",
    "        :param transform: torch.transform，数据预处理\n",
    "        \"\"\"\n",
    "        self.label_name = {\"1\": 0, \"100\": 1}\n",
    "        self.data_info = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        now = self.data_info.iloc[index, :]\n",
    "        X = now[:-1]\n",
    "        y = now[-1]\n",
    "        # X = X.apply(lambda x : (x-np.min(x))/(np.max(x)-np.min(x)))\n",
    "        # print(X)\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        X = X.astype(np.float32)\n",
    "        y = y.astype(np.float32)\n",
    "        X = torch.tensor(X)\n",
    "        y = torch.tensor(y)\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X) \n",
    "        \n",
    "        \n",
    "        return X,y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "#previous transform\n",
    "# transform = transforms.Compose([transforms.Normalize([0.5],[0.5])])\n",
    "#download the dataset\n",
    "\n",
    "train_dataset = PilotDataset(normal_train)\n",
    "test_dataset = PilotDataset(normal_test)\n",
    "\n",
    "# declare dataloader \n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size,\n",
    "                          shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, n_hidden_1,n_hidden_2, n_hidden_3,n_hidden_4,out_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1),nn.BatchNorm1d(n_hidden_1), nn.Dropout(0.2))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2),nn.BatchNorm1d(n_hidden_2),nn.Dropout(0.2))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, n_hidden_3),nn.BatchNorm1d(n_hidden_3))\n",
    "        self.layer4 = nn.Sequential(nn.Linear(n_hidden_3, n_hidden_4),nn.BatchNorm1d(n_hidden_4))\n",
    "        self.layer5 = nn.Sequential(nn.Linear(n_hidden_4, out_dim),nn.BatchNorm1d(out_dim))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        x = (self.layer5(x))\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() is True else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "model = Net(4, 8, 16, 16, 4,1)\n",
    "model.to(device)\n",
    "\n",
    "#declare Loss Function and optimizer\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(),lr,momentum)\n",
    "optimizer = optim.Adam(model.parameters(),lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Train Model\n",
    "\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces= []\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    #动态修改学习率参数\n",
    "    if epoch%5 == 0:\n",
    "        optimizer.param_groups[0]['lr'] *= 0.1\n",
    "    for X,label in train_loader:\n",
    "        X = X.to(device)\n",
    "        label = label.to(device)\n",
    "        #forward\n",
    "        out = model(X)\n",
    "        loss = criterion(out,label)\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() #loss是个标量，在pytorch里用item取出这个唯一的元素\n",
    "        #calculate the accuracy of this training\n",
    "        # _, pred = torch.max(out,1) #按行取最大值 也就是预测的那个数\n",
    "        outcome = abs(out-label) <= 0.1\n",
    "        num_correct =outcome.sum().item()\n",
    "        acc = num_correct/X.shape[0]\n",
    "        train_acc+=acc\n",
    "        \n",
    "    losses.append(train_loss/ len(train_loader))\n",
    "    acces.append(train_acc/ len(train_loader))\n",
    "    \n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    \n",
    "    model.eval() #Model change to eval mode\n",
    "    for img,label in test_loader:\n",
    "        img=img.to(device)\n",
    "        label = label.to(device)\n",
    "        # img = img.view(img.size(0),-1)\n",
    "        \n",
    "        out = model(img)\n",
    "        loss = criterion(out,label)\n",
    "        eval_loss+=loss.item()\n",
    "        \n",
    "        # _,pred = out.max(1)\n",
    "        num_cor = (abs(out-label) <= 0.2).sum().item()\n",
    "        acc = num_cor/img.shape[0]\n",
    "        eval_acc+=acc\n",
    "        \n",
    "    eval_losses.append(eval_loss/len(test_loader))\n",
    "    eval_acces.append(eval_acc / len(test_loader))\n",
    "    print(\"epoch:{}, Train loss: {:.4f}, Train acc: {:.4f}, Test loss: {:.4f}. Test acc:{:.4f}\\n\".format(epoch, train_loss/len(train_loader), train_acc/len(train_loader), eval_loss/len(test_loader), eval_acc/len(test_loader)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "60000\n",
      "15000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(train_x.shape[0]*train_x.shape[1])\n",
    "print(len(train_x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-108f62361942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mhere\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-075465942093>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# X = X.apply(lambda x : (x-np.min(x))/(np.max(x)-np.min(x)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    923\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1504\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1506\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1507\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[0mCheck\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0macross\u001b[0m \u001b[0mmy\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \"\"\"\n\u001b[1;32m--> 751\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\Pytorch_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_key_length\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Too many indexers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Too many indexers"
     ],
     "ename": "IndexingError",
     "evalue": "Too many indexers",
     "output_type": "error"
    }
   ],
   "source": [
    "for X,y in train_loader:\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    out = model(X)\n",
    "    here = (abs(out-y) <= 0.01)\n",
    "    # print(X)\n",
    "    break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([[29.7431]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model.eval()\n",
    "now = np.array([[0.90,0.62,0.533333333,0.866666667\n",
    "]])\n",
    "now = now.astype(np.float32)\n",
    "now = torch.tensor(now).to(device)\n",
    "out = model(now)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "layer1.0.weight tensor([[-0.1704, -0.5773, -0.1374,  0.7331],\n",
      "        [ 0.8228,  0.4425, -0.1597, -0.2100],\n",
      "        [-0.2074, -0.0989, -0.1212, -0.7224],\n",
      "        [ 0.1347,  0.6153, -0.0672,  0.0894],\n",
      "        [-0.7915,  0.0261,  0.0704, -0.5685],\n",
      "        [-0.6218,  0.0359,  0.0531,  0.2521],\n",
      "        [ 0.5029, -0.1751,  0.3792, -0.4011],\n",
      "        [-0.1148, -0.1068, -0.6935, -0.1060]], device='cuda:0')\n",
      "layer1.0.bias tensor([-0.4764, -0.1074,  0.3954, -0.4913, -0.4690,  0.3869, -0.2075, -0.4838],\n",
      "       device='cuda:0')\n",
      "layer1.1.weight tensor([0.5731, 1.3303, 1.5022, 1.0008, 1.3142, 0.5325, 1.4713, 0.5870],\n",
      "       device='cuda:0')\n",
      "layer1.1.bias tensor([ 0.0934,  0.1074,  0.2824,  0.1254,  0.1056, -0.5303,  0.3865, -0.4560],\n",
      "       device='cuda:0')\n",
      "layer1.1.running_mean tensor([-0.3594,  0.2620, -0.3071, -0.1538, -1.2174,  0.2824, -0.0977, -1.0151],\n",
      "       device='cuda:0')\n",
      "layer1.1.running_var tensor([0.0314, 0.0694, 0.0185, 0.0150, 0.0685, 0.0349, 0.0370, 0.0145],\n",
      "       device='cuda:0')\n",
      "layer1.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer2.0.weight tensor([[-3.3182e-01, -9.6363e-02,  1.5523e-04, -2.4014e-01,  6.5642e-01,\n",
      "          8.9448e-02, -4.5606e-01,  3.9878e-03],\n",
      "        [ 5.0175e-01,  2.4239e-01, -6.7045e-01,  4.1271e-01, -1.7316e-01,\n",
      "         -8.8906e-02,  4.1742e-02, -2.6053e-02],\n",
      "        [ 6.7181e-03, -5.5831e-01, -2.7104e-01, -5.2206e-01,  2.4611e-01,\n",
      "         -3.8514e-02,  5.5651e-01,  1.5773e-01],\n",
      "        [-3.6683e-01, -1.3475e-01,  1.7576e-01, -5.0210e-01, -1.4208e-01,\n",
      "          3.0048e-01,  1.7463e-01, -5.0387e-01],\n",
      "        [ 1.9956e-01, -6.2256e-02,  5.3575e-01,  1.3131e-02,  6.0453e-01,\n",
      "         -4.4618e-03, -4.2481e-01,  4.3562e-01],\n",
      "        [ 6.0290e-02, -1.5693e-01, -6.1248e-01,  3.1952e-01,  2.9466e-02,\n",
      "          4.9488e-02, -7.6776e-01, -1.3256e-01],\n",
      "        [-6.8331e-01,  2.3839e-01,  5.2966e-01, -3.7596e-01, -4.9784e-01,\n",
      "         -3.7949e-01,  6.6880e-02, -2.1791e-01],\n",
      "        [-3.1443e-01, -8.2220e-02,  4.4000e-01, -2.1694e-01,  8.9747e-02,\n",
      "         -4.1788e-01, -1.6524e-02, -2.9492e-01],\n",
      "        [-2.2181e-01,  5.1403e-01,  2.9315e-01,  3.4203e-01, -4.0259e-01,\n",
      "         -4.7969e-01, -2.9582e-01, -1.0178e-01],\n",
      "        [-4.3328e-01,  1.7566e-01,  2.9993e-01, -5.8865e-01, -3.7721e-01,\n",
      "         -4.9651e-01,  1.6517e-01, -1.7372e-01],\n",
      "        [ 6.4066e-01, -5.9620e-01, -5.7458e-01,  5.1986e-02, -2.4352e-02,\n",
      "          3.9441e-02,  5.0021e-01, -6.3130e-02],\n",
      "        [-5.0399e-01, -1.3458e-01, -4.3892e-01, -7.3958e-02,  2.6032e-04,\n",
      "         -3.2996e-01, -5.7196e-01,  3.4041e-01],\n",
      "        [-2.3060e-01,  6.6432e-01,  4.1403e-01,  3.0566e-01, -5.4690e-01,\n",
      "         -1.6953e-01, -1.8250e-01,  1.6644e-01],\n",
      "        [-9.0597e-02, -3.1249e-01,  6.4612e-01, -7.5613e-02,  2.7931e-01,\n",
      "          3.6901e-01, -3.2697e-01, -2.7102e-01],\n",
      "        [ 3.3903e-02,  4.8914e-01, -3.5395e-01,  3.8384e-01,  4.2716e-01,\n",
      "         -2.0562e-01,  5.4904e-01, -1.1000e-01],\n",
      "        [ 4.5698e-01, -3.0392e-01, -2.9535e-01, -1.4643e-01,  2.0649e-02,\n",
      "         -6.0200e-02, -1.1079e-01,  1.0405e-01]], device='cuda:0')\n",
      "layer2.0.bias tensor([ 0.1609, -0.2604,  0.2315, -0.1994, -0.0879, -0.1576,  0.1631, -0.2533,\n",
      "        -0.2020, -0.2296,  0.0370, -0.1899, -0.1699,  0.0855,  0.1271, -0.3357],\n",
      "       device='cuda:0')\n",
      "layer2.1.weight tensor([0.6459, 1.2854, 0.7342, 1.3112, 0.7139, 1.1224, 1.2644, 1.3801, 0.5933,\n",
      "        1.4316, 0.7094, 1.0561, 0.6984, 1.4904, 0.7095, 0.6939],\n",
      "       device='cuda:0')\n",
      "layer2.1.bias tensor([-0.4614,  0.4762, -0.2557,  0.1407, -0.3294,  0.1668,  0.0228,  0.3336,\n",
      "        -0.4889,  0.3998, -0.2970,  0.2021, -0.3032, -0.3936, -0.2769, -0.3550],\n",
      "       device='cuda:0')\n",
      "layer2.1.running_mean tensor([-0.0798, -0.3528,  0.0277, -0.4535,  0.3833, -1.1703,  0.0732, -0.1551,\n",
      "        -0.0570, -0.4177, -0.1878, -1.2514,  0.1761,  0.2184,  1.0635, -0.7765],\n",
      "       device='cuda:0')\n",
      "layer2.1.running_var tensor([1.0386, 1.3395, 0.7114, 0.2929, 1.6587, 1.7615, 0.6486, 0.4611, 0.5678,\n",
      "        0.4981, 0.7310, 0.7859, 0.8512, 1.4752, 1.0696, 0.3594],\n",
      "       device='cuda:0')\n",
      "layer2.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer3.0.weight tensor([[ 6.3473e-02,  2.7825e-01,  3.4737e-01,  5.6655e-01,  5.5478e-02,\n",
      "         -3.0364e-01,  3.8646e-01,  3.6436e-01,  1.0880e-01,  6.0734e-01,\n",
      "         -6.6206e-04, -3.8709e-02,  4.1097e-02,  3.6043e-01,  2.2058e-01,\n",
      "         -1.1705e-01],\n",
      "        [ 2.2529e-01, -3.6029e-01, -3.6791e-01,  4.9826e-03,  4.4329e-01,\n",
      "          9.4135e-02,  2.9712e-02,  5.1345e-01, -1.1525e-01, -4.7601e-02,\n",
      "         -3.5697e-01,  2.4082e-01, -3.7127e-01,  4.9113e-02, -2.5460e-01,\n",
      "         -6.8777e-01],\n",
      "        [-8.3964e-02,  1.3185e-01,  1.4259e-01,  4.8426e-01,  1.2014e-01,\n",
      "         -2.3971e-01,  3.7089e-01,  2.9071e-01,  2.2036e-01,  3.9506e-01,\n",
      "          2.3529e-01, -5.1589e-01,  2.6035e-01,  2.8364e-01,  1.6668e-01,\n",
      "         -3.9639e-01],\n",
      "        [ 2.9302e-01,  2.7382e-01,  1.5118e-01, -4.8791e-01,  1.2800e-01,\n",
      "          4.4492e-01, -8.3536e-01, -8.9086e-02,  1.7284e-01, -2.8218e-01,\n",
      "         -8.3929e-02,  6.2087e-02, -4.1690e-02, -1.3063e-01,  3.1179e-02,\n",
      "         -1.6710e-01],\n",
      "        [-2.1665e-01, -4.5309e-02,  1.0334e-01,  2.9485e-01,  5.5384e-01,\n",
      "         -2.7118e-01,  2.7256e-02,  4.5740e-01,  1.6557e-01,  1.1098e-01,\n",
      "         -1.1520e-01, -2.6444e-01,  4.3574e-01,  6.4878e-01, -2.4803e-01,\n",
      "         -2.5270e-01],\n",
      "        [-1.2112e-01, -2.1497e-01, -2.7698e-01,  5.2860e-01,  1.3190e-01,\n",
      "         -2.1307e-01,  2.9324e-01,  5.1686e-01, -8.7297e-02,  3.7724e-01,\n",
      "         -2.2590e-01, -2.6605e-01, -7.0816e-02,  6.1070e-01, -2.0765e-01,\n",
      "         -3.0239e-01],\n",
      "        [ 4.1087e-01,  4.7854e-02,  2.5467e-01,  4.7741e-01,  5.2300e-01,\n",
      "         -1.7756e-01,  2.8234e-01,  5.5566e-01,  5.2697e-01,  3.6931e-01,\n",
      "          1.9872e-01, -2.9297e-01, -6.7265e-02,  5.0356e-01,  5.1797e-02,\n",
      "          2.5631e-02],\n",
      "        [ 1.4700e-01, -5.0612e-01, -5.6625e-02,  5.0083e-01, -2.6389e-01,\n",
      "         -1.1454e-01,  3.3630e-01,  3.1792e-02, -3.1559e-01,  4.3611e-01,\n",
      "         -3.2113e-01, -1.6765e-01, -1.0163e-01, -2.4432e-01,  1.2530e-03,\n",
      "         -3.7362e-01]], device='cuda:0')\n",
      "layer3.0.bias tensor([-0.0636, -0.2272, -0.0191, -0.2353,  0.2085,  0.0846, -0.1402,  0.1494],\n",
      "       device='cuda:0')\n",
      "layer3.1.weight tensor([1.1962, 0.7535, 1.4190, 0.9584, 1.4792, 0.9023, 1.1908, 0.6523],\n",
      "       device='cuda:0')\n",
      "layer3.1.bias tensor([ 0.2510, -0.2858, -0.2429,  0.2300, -0.1950, -0.1865, -0.5228, -0.4150],\n",
      "       device='cuda:0')\n",
      "layer3.1.running_mean tensor([ 1.4534, -0.2178,  0.8710, -0.7143,  0.7990,  0.8203,  1.1587,  0.1188],\n",
      "       device='cuda:0')\n",
      "layer3.1.running_var tensor([3.6660, 1.4615, 3.0070, 2.8127, 2.8794, 4.4829, 4.2658, 1.9945],\n",
      "       device='cuda:0')\n",
      "layer3.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer4.0.weight tensor([[ 0.0462, -0.6735, -0.1602,  0.2207, -0.5606, -0.2160, -0.3605,  0.1390],\n",
      "        [ 0.3319, -0.7228,  0.2135, -0.1168, -0.1294, -0.7215, -0.5531, -0.4144],\n",
      "        [-0.4875,  0.2345, -0.4200,  0.4573, -0.2521, -0.0282,  0.1496,  0.0212],\n",
      "        [-0.5258, -0.2138,  0.0161,  0.0325, -0.5123, -0.4114, -0.3527, -0.3751]],\n",
      "       device='cuda:0')\n",
      "layer4.0.bias tensor([-0.1947, -0.0441,  0.1069,  0.3396], device='cuda:0')\n",
      "layer4.1.weight tensor([0.9174, 0.5857, 1.0869, 0.8126], device='cuda:0')\n",
      "layer4.1.bias tensor([ 0.0535, -0.4015,  0.1007, -0.2723], device='cuda:0')\n",
      "layer4.1.running_mean tensor([-0.6599, -0.4300, -0.1558, -0.4689], device='cuda:0')\n",
      "layer4.1.running_var tensor([1.9996, 0.8827, 1.1682, 2.8725], device='cuda:0')\n",
      "layer4.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer5.0.weight tensor([[0.1864, 0.1083, 0.4181, 0.0434]], device='cuda:0')\n",
      "layer5.0.bias tensor([0.2547], device='cuda:0')\n",
      "layer5.1.weight tensor([-1.4796e-07], device='cuda:0')\n",
      "layer5.1.bias tensor([29.7431], device='cuda:0')\n",
      "layer5.1.running_mean tensor([0.5164], device='cuda:0')\n",
      "layer5.1.running_var tensor([0.0352], device='cuda:0')\n",
      "layer5.1.num_batches_tracked tensor(7820, device='cuda:0')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for layer,param in model.state_dict().items(): # param is weight or bias(Tensor) \n",
    "\tprint (layer,param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "layer1.0.weight tensor([[-0.0160,  0.5516,  0.4051, -0.6863],\n",
      "        [-0.8919,  0.0289,  0.4211, -0.2373],\n",
      "        [ 0.2575,  0.3322, -0.0543, -0.4241],\n",
      "        [-0.5136, -0.2577, -0.1332,  0.2500],\n",
      "        [-0.4385,  0.3830, -0.0396, -0.0650],\n",
      "        [ 0.0504,  0.1444,  0.3351, -0.6784],\n",
      "        [-0.0125, -0.7866,  0.0588, -0.2121],\n",
      "        [ 0.2830,  0.1172,  0.8781, -0.1618]], device='cuda:0')\n",
      "layer1.0.bias tensor([ 0.1227,  0.0983,  0.2334, -0.0382, -0.1132,  0.0991,  0.3353,  0.0331],\n",
      "       device='cuda:0')\n",
      "layer1.1.weight tensor([0.4929, 0.6888, 0.9110, 1.2355, 0.6976, 1.4557, 0.6501, 1.4008],\n",
      "       device='cuda:0')\n",
      "layer1.1.bias tensor([-0.5180, -0.1785, -0.3469,  0.1871, -0.4024,  0.1308, -0.3546,  0.4826],\n",
      "       device='cuda:0')\n",
      "layer1.1.running_mean tensor([ 0.0704, -0.2927,  0.1774, -0.3002, -0.2521, -0.1100, -0.0953,  0.5665],\n",
      "       device='cuda:0')\n",
      "layer1.1.running_var tensor([0.0356, 0.0808, 0.0138, 0.0295, 0.0201, 0.0252, 0.0218, 0.0374],\n",
      "       device='cuda:0')\n",
      "layer1.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer2.0.weight tensor([[ 0.3212, -0.3711,  0.1016, -0.2879, -0.3941,  0.6178,  0.2626,  0.1674],\n",
      "        [-0.2951, -0.1084, -0.2532, -0.4389,  0.0978,  0.7258, -0.0184,  0.3221],\n",
      "        [ 0.5577, -0.2626, -0.3100, -0.4523, -0.0208,  0.3512,  0.0465,  0.4384],\n",
      "        [ 0.3684, -0.0174,  0.5124, -0.5810,  0.3071,  0.1626, -0.0172,  0.3159],\n",
      "        [-0.0129,  0.5496,  0.7127, -0.0699, -0.0441,  0.0765, -0.1124, -0.1229],\n",
      "        [ 0.0666, -0.1382, -0.4734, -0.6591, -0.1826,  0.2185, -0.1020,  0.5028],\n",
      "        [ 0.1387, -0.0796, -0.7173, -0.4718,  0.2575,  0.0024, -0.0795,  0.7053],\n",
      "        [ 0.2864,  0.1450,  0.2261, -0.3568, -0.0919,  0.3640, -0.4899,  0.3796],\n",
      "        [ 0.3229, -0.0828,  0.1428, -0.4909, -0.3933,  0.1946, -0.1442,  0.3091],\n",
      "        [ 0.2482, -0.0768, -0.2212, -0.5767, -0.0318,  0.5440,  0.3350,  0.6223],\n",
      "        [ 0.5971, -0.0114, -0.0842, -0.4155,  0.2298,  0.5145, -0.1430,  0.3842],\n",
      "        [-0.0732,  0.0227,  0.1042,  0.1162,  0.4392,  0.5895, -0.1606,  0.0474],\n",
      "        [-0.2139, -0.0664,  0.1722, -0.3238,  0.2509, -0.1250, -0.1160,  0.7156],\n",
      "        [-0.4147, -0.0490, -0.2578, -0.5491, -0.1144, -0.1103,  0.2323,  0.7153],\n",
      "        [ 0.3712,  0.1314, -0.3043, -0.2110,  0.1670,  0.3882,  0.0348,  0.3841],\n",
      "        [ 0.1297,  0.4719,  0.7287, -0.3025,  0.2948,  0.4642, -0.2017,  0.3214]],\n",
      "       device='cuda:0')\n",
      "layer2.0.bias tensor([ 0.0312,  0.2769, -0.2647,  0.2771,  0.2459, -0.1470,  0.0534,  0.0045,\n",
      "         0.3136,  0.0304, -0.3061,  0.2235, -0.1148,  0.0757,  0.3102, -0.1553],\n",
      "       device='cuda:0')\n",
      "layer2.1.weight tensor([0.8218, 1.2781, 1.3170, 0.7775, 1.0945, 1.3703, 0.7020, 0.7313, 0.4198,\n",
      "        0.9790, 1.5158, 0.6094, 1.2083, 1.3188, 1.2814, 0.6790],\n",
      "       device='cuda:0')\n",
      "layer2.1.bias tensor([ 0.1153, -0.3606,  0.2992, -0.3404, -0.3407,  0.0156, -0.3636, -0.1230,\n",
      "        -0.5561, -0.4460,  0.3026, -0.5098,  0.1556,  0.0778,  0.1335, -0.4838],\n",
      "       device='cuda:0')\n",
      "layer2.1.running_mean tensor([ 0.2985,  0.6125, -0.0798,  0.4221,  0.3956, -0.1900,  0.1756,  0.3167,\n",
      "         0.3305,  0.4734,  0.0656,  0.7423,  0.1965,  0.1586,  0.7179,  0.4546],\n",
      "       device='cuda:0')\n",
      "layer2.1.running_var tensor([1.1040, 1.4531, 1.1264, 1.0178, 0.1391, 1.2051, 1.0378, 1.0624, 0.8373,\n",
      "        2.2402, 1.3441, 0.5324, 0.9734, 1.1286, 0.7916, 1.3615],\n",
      "       device='cuda:0')\n",
      "layer2.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer3.0.weight tensor([[-0.4387, -0.1008, -0.5460,  0.1183,  0.1410, -0.2513, -0.6486, -0.3778,\n",
      "         -0.4052,  0.1213, -0.4287,  0.3882, -0.1614, -0.4814, -0.3041,  0.2269],\n",
      "        [-0.0474,  0.1232, -0.0017, -0.3659, -0.1721,  0.5036,  0.1405, -0.2397,\n",
      "         -0.0440,  0.4575,  0.5308,  0.1335,  0.4098,  0.3309, -0.1475, -0.2891],\n",
      "        [ 0.3299,  0.6104,  0.2850, -0.0318,  0.4180,  0.2847,  0.1240,  0.1435,\n",
      "         -0.0299, -0.2630,  0.6485,  0.2115,  0.6420,  0.4672,  0.2944, -0.0551],\n",
      "        [-0.0599,  0.0216,  0.1624, -0.2931, -0.0010,  0.0376,  0.2738,  0.0017,\n",
      "          0.1642,  0.2322,  0.1490, -0.1404,  0.3316,  0.6774, -0.1034, -0.0570],\n",
      "        [-0.1295,  0.0571,  0.1053,  0.2545, -0.0324,  0.6190,  0.2245,  0.0515,\n",
      "         -0.1506,  0.2373, -0.1060, -0.2743,  0.5555,  0.3936,  0.3905, -0.0047],\n",
      "        [ 0.1977,  0.3851,  0.5016,  0.1683,  0.6311,  0.2340,  0.0530,  0.1258,\n",
      "          0.0054, -0.3382,  0.5841,  0.0789,  0.2772,  0.0843,  0.3405,  0.3679],\n",
      "        [-0.0512,  0.3201,  0.4039,  0.0351, -0.2984,  0.6206,  0.1593,  0.3601,\n",
      "          0.0046,  0.2530,  0.5259,  0.3661,  0.2178,  0.0105,  0.4245, -0.4243],\n",
      "        [-0.4809, -0.2062, -0.2849, -0.5678,  0.0020, -0.1369, -0.3921,  0.0340,\n",
      "          0.0647, -0.0162, -0.6358, -0.3022, -0.3721, -0.4754, -0.6199, -0.0060],\n",
      "        [-0.0447,  0.4122,  0.2031, -0.2584, -0.4096,  0.4706,  0.4353,  0.0568,\n",
      "         -0.5492,  0.4938,  0.2316,  0.0416,  0.2118,  0.2131,  0.5698, -0.2888],\n",
      "        [-0.0899,  0.4649,  0.4756, -0.1729, -0.0667,  0.4208,  0.1927,  0.2717,\n",
      "         -0.0351,  0.2326,  0.6195,  0.2129,  0.1951,  0.1062,  0.5811, -0.1997],\n",
      "        [-0.5455, -0.2365, -0.1989, -0.6280,  0.2951, -0.1852, -0.2371, -0.0987,\n",
      "         -0.2188, -0.5035, -0.4852, -0.0635, -0.3858, -0.4522, -0.3698, -0.5317],\n",
      "        [ 0.4158,  0.5159,  0.3216, -0.1435,  0.5579,  0.1956,  0.0163,  0.3887,\n",
      "          0.3955, -0.1778,  0.4016,  0.4670,  0.2990,  0.2226,  0.3939, -0.0485],\n",
      "        [-0.0009, -0.4563, -0.1665, -0.2241, -0.3822, -0.0180, -0.5929, -0.7217,\n",
      "          0.2916, -0.0835, -0.5324, -0.3886, -0.4684, -0.6401, -0.4066, -0.1489],\n",
      "        [-0.0707,  0.1637, -0.0023, -0.3772, -0.1106,  0.4855, -0.0269,  0.0207,\n",
      "         -0.0517,  0.0888,  0.5737,  0.0102, -0.0790, -0.1075,  0.1890, -0.2081],\n",
      "        [-0.2084,  0.0875,  0.5603, -0.0343, -0.2084,  0.5872,  0.4303,  0.3266,\n",
      "          0.2390,  0.5431,  0.4665,  0.1151,  0.3371,  0.2445,  0.3918, -0.1728],\n",
      "        [ 0.6113,  0.2021, -0.3698,  0.0969,  0.2139, -0.1198, -0.4070, -0.4711,\n",
      "         -0.2797,  0.4217, -0.2922,  0.3295, -0.6773, -0.6102, -0.8153,  0.3059]],\n",
      "       device='cuda:0')\n",
      "layer3.0.bias tensor([-0.0263,  0.1206, -0.0548, -0.1570,  0.2185,  0.1866, -0.0653,  0.1243,\n",
      "         0.0186,  0.0010,  0.1196, -0.1474,  0.1555, -0.0497, -0.1914,  0.0283],\n",
      "       device='cuda:0')\n",
      "layer3.1.weight tensor([0.7445, 1.2899, 1.2977, 1.1729, 0.9624, 0.6438, 1.5942, 0.4940, 0.7919,\n",
      "        0.7020, 0.7416, 0.3342, 0.4549, 1.4784, 1.5138, 0.4630],\n",
      "       device='cuda:0')\n",
      "layer3.1.bias tensor([ 0.4677, -0.3632, -0.4416,  0.0025,  0.3899, -0.2769, -0.1821,  0.0728,\n",
      "         0.1706, -0.4098,  0.4571, -0.5154, -0.2284, -0.0910,  0.2867, -0.5044],\n",
      "       device='cuda:0')\n",
      "layer3.1.running_mean tensor([-1.4938,  1.0178,  1.8956,  0.5744,  1.3053,  1.8021,  1.3520, -1.7552,\n",
      "         1.1745,  1.6117, -1.6249,  1.4722, -1.7781,  0.5013,  1.4380, -1.2163],\n",
      "       device='cuda:0')\n",
      "layer3.1.running_var tensor([ 7.2564,  2.9304, 11.5864,  1.8563,  4.2292,  8.1409,  7.7947, 12.2763,\n",
      "         5.7068,  9.5323, 11.8405,  8.3839, 12.6884,  1.3690,  9.8944,  5.8929],\n",
      "       device='cuda:0')\n",
      "layer3.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer4.0.weight tensor([[ 0.3784, -0.3698, -0.2489, -0.3313, -0.0849, -0.2845, -0.1927,  0.1104,\n",
      "         -0.1292,  0.0624,  0.4570,  0.2313, -0.2383, -0.0141, -0.3249,  0.2793],\n",
      "        [-0.0647, -0.6378, -0.3158,  0.2360, -0.3690,  0.4736, -0.4950,  0.1281,\n",
      "         -0.4055, -0.6032, -0.2117, -0.1900, -0.0447, -0.5823, -0.5625, -0.2896],\n",
      "        [-0.5411, -0.0249,  0.3217, -0.4489,  0.3073,  0.4678,  0.2282, -0.1746,\n",
      "          0.1159,  0.5593, -0.3554,  0.3188,  0.2943,  0.3346,  0.2609, -0.1073],\n",
      "        [-0.0418, -0.3471, -0.6377,  0.1442, -0.6597,  0.0819, -0.6430,  0.0825,\n",
      "         -0.3507, -0.3210, -0.0421, -0.4838,  0.2429, -0.5778, -0.6430, -0.3507]],\n",
      "       device='cuda:0')\n",
      "layer4.0.bias tensor([ 0.1117, -0.0391, -0.0955,  0.0568], device='cuda:0')\n",
      "layer4.1.weight tensor([0.5207, 0.9593, 0.5684, 1.0810], device='cuda:0')\n",
      "layer4.1.bias tensor([-0.4184,  0.0518, -0.3069,  0.1357], device='cuda:0')\n",
      "layer4.1.running_mean tensor([-0.1127, -1.6062,  0.0072, -1.7118], device='cuda:0')\n",
      "layer4.1.running_var tensor([ 4.1788, 11.6847,  4.1299, 17.1263], device='cuda:0')\n",
      "layer4.1.num_batches_tracked tensor(7820, device='cuda:0')\n",
      "layer5.0.weight tensor([[-0.0832, -0.2069,  0.2395, -0.3224]], device='cuda:0')\n",
      "layer5.0.bias tensor([0.1089], device='cuda:0')\n",
      "layer5.1.weight tensor([1.5421e-08], device='cuda:0')\n",
      "layer5.1.bias tensor([29.7431], device='cuda:0')\n",
      "layer5.1.running_mean tensor([-0.0754], device='cuda:0')\n",
      "layer5.1.running_var tensor([0.0362], device='cuda:0')\n",
      "layer5.1.num_batches_tracked tensor(7820, device='cuda:0')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "for layer,param in model.state_dict().items(): # param is weight or bias(Tensor) \n",
    "\tprint (layer,param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch_gpu",
   "language": "python",
   "display_name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}